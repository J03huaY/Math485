{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e657028-f90a-42ff-b7cc-656f7d216926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217bf209-c60a-4836-acc9-3a9f178dfc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_name = \"osdg-community-data-v2024-04-01.csv\"\n",
    "text_df = pd.read_csv(text_file_name,sep = \"\\t\",  quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10943ba-b5fb-4595-b764-d83254e4dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.drop(text_df.columns.values[0],axis = 1, inplace=True)\n",
    "text_df = text_df.query(\"agreement > 0.5 and (labels_positive - labels_negative) > 2\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3b451-f89e-458a-965f-5209698dba2a",
   "metadata": {},
   "source": [
    "After cleaning the data, we get the text data then define the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5adc4-044b-4b16-b5eb-fbb30e00dbc8",
   "metadata": {},
   "source": [
    "Since there is no labels in the text_df, we need to define a function to add the sdg labels to each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770bbdbb-de91-4d98-b9ee-78ea3d68c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sdg_labels(text):\n",
    "    \"\"\"\n",
    "    Assign SDG labels to the text based on keywords related to each SDG.\n",
    "    Each SDG can be associated with multiple keywords, and a text can be labeled with more than one SDG.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to hold SDG labels\n",
    "    labels = []\n",
    "\n",
    "    # SDG 1: No Poverty\n",
    "    if \"poverty\" in text.lower() or \"income inequality\" in text.lower() or \"economic hardship\" in text.lower():\n",
    "        labels.append(1)  # No Poverty\n",
    "\n",
    "    # SDG 2: Zero Hunger\n",
    "    if \"hunger\" in text.lower() or \"food security\" in text.lower() or \"malnutrition\" in text.lower():\n",
    "        labels.append(2)  # Zero Hunger\n",
    "\n",
    "    # SDG 3: Good Health and Well-being\n",
    "    if \"health\" in text.lower() or \"disease\" in text.lower() or \"mental health\" in text.lower():\n",
    "        labels.append(3)  # Good Health and Well-being\n",
    "\n",
    "    # SDG 4: Quality Education\n",
    "    if \"education\" in text.lower() or \"learning\" in text.lower() or \"school\" in text.lower():\n",
    "        labels.append(4)  # Quality Education\n",
    "\n",
    "    # SDG 5: Gender Equality\n",
    "    if \"gender\" in text.lower() or \"women's rights\" in text.lower() or \"equality\" in text.lower():\n",
    "        labels.append(5)  # Gender Equality\n",
    "\n",
    "    # SDG 6: Clean Water and Sanitation\n",
    "    if \"water\" in text.lower() or \"sanitation\" in text.lower() or \"clean water\" in text.lower():\n",
    "        labels.append(6)  # Clean Water and Sanitation\n",
    "\n",
    "    # SDG 7: Affordable and Clean Energy\n",
    "    if \"energy\" in text.lower() or \"renewable\" in text.lower() or \"solar power\" in text.lower() or \"clean energy\" in text.lower():\n",
    "        labels.append(7)  # Affordable and Clean Energy\n",
    "\n",
    "    # SDG 8: Decent Work and Economic Growth\n",
    "    if \"employment\" in text.lower() or \"job\" in text.lower() or \"economic growth\" in text.lower():\n",
    "        labels.append(8)  # Decent Work and Economic Growth\n",
    "\n",
    "    # SDG 9: Industry, Innovation and Infrastructure\n",
    "    if \"innovation\" in text.lower() or \"infrastructure\" in text.lower() or \"industry\" in text.lower():\n",
    "        labels.append(9)  # Industry, Innovation and Infrastructure\n",
    "\n",
    "    # SDG 10: Reduced Inequalities\n",
    "    if \"inequality\" in text.lower() or \"discrimination\" in text.lower() or \"social justice\" in text.lower():\n",
    "        labels.append(10)  # Reduced Inequalities\n",
    "\n",
    "    # SDG 11: Sustainable Cities and Communities\n",
    "    if \"urban\" in text.lower() or \"city\" in text.lower() or \"community\" in text.lower() or \"sustainable development\" in text.lower():\n",
    "        labels.append(11)  # Sustainable Cities and Communities\n",
    "\n",
    "    # SDG 12: Responsible Consumption and Production\n",
    "    if \"sustainability\" in text.lower() or \"responsible consumption\" in text.lower() or \"waste reduction\" in text.lower():\n",
    "        labels.append(12)  # Responsible Consumption and Production\n",
    "\n",
    "    # SDG 13: Climate Action\n",
    "    if \"climate change\" in text.lower() or \"global warming\" in text.lower() or \"carbon footprint\" in text.lower():\n",
    "        labels.append(13)  # Climate Action\n",
    "\n",
    "    # SDG 14: Life Below Water\n",
    "    if \"ocean\" in text.lower() or \"marine life\" in text.lower() or \"fisheries\" in text.lower():\n",
    "        labels.append(14)  # Life Below Water\n",
    "\n",
    "    # SDG 15: Life on Land\n",
    "    if \"biodiversity\" in text.lower() or \"conservation\" in text.lower() or \"wildlife\" in text.lower() or \"deforestation\" in text.lower():\n",
    "        labels.append(15)  # Life on Land\n",
    "\n",
    "    # SDG 16: Peace, Justice and Strong Institutions\n",
    "    if \"justice\" in text.lower() or \"peace\" in text.lower() or \"corruption\" in text.lower() or \"rule of law\" in text.lower():\n",
    "        labels.append(16)  # Peace, Justice and Strong Institutions\n",
    "\n",
    "    # SDG 17: Partnerships for the Goals\n",
    "    if \"partnerships\" in text.lower() or \"collaboration\" in text.lower() or \"global cooperation\" in text.lower():\n",
    "        labels.append(17)  # Partnerships for the Goals\n",
    "\n",
    "    # If no SDGs match, return a default value (optional)\n",
    "    return labels if labels else [0]  # Default to [0] if no SDG matches\n",
    "\n",
    "\n",
    "\n",
    "text_df['sdg_labels'] = text_df.text.apply(assign_sdg_labels)\n",
    "\n",
    "corpus = text_df[['text', 'sdg_labels']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc9c56-e399-4a00-a98a-72db1d25e693",
   "metadata": {},
   "source": [
    "For this function, we use unigram only and tfid vectorizor\n",
    "Function definiton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cc19ac-529c-468c-88f8-b7711c3ad394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def sdg_classify_tfid_unigram(corpus, classifier_algorithm):\n",
    " \n",
    "\n",
    "    # Convert SDG labels into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_binary = mlb.fit_transform(corpus['sdg_labels'])\n",
    "    X = corpus['text']\n",
    "    y = y_binary\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1), min_df=500, max_features=5000, stop_words='english')\n",
    "    X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "    # train and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    try:\n",
    "        # Check if the classifier accepts a random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm(random_state=42))\n",
    "    except TypeError:\n",
    "        # If not, initialize it without the random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm())\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Use `predict_proba` for classifiers that support it (e.g., MLPClassifier, MultinomialNB)\n",
    "        y_pred_proba = classifier.predict_proba(X_test)\n",
    "        threshold = 0.3\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Use `predict_log_proba` for classifiers that support it (e.g., MultinomialNB)\n",
    "            y_pred_log_proba = classifier.predict_log_proba(X_test)\n",
    "            y_pred_proba = np.exp(y_pred_log_proba)  # Convert log probabilities to probabilities\n",
    "            threshold = 0.3\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        except AttributeError:\n",
    "            # If neither `predict_proba` nor `predict_log_proba` is available, use `predict`\n",
    "            y_pred = classifier.predict(X_test)\n",
    "        \n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63385bed-9ce9-46c0-b796-2a21ea0e8c49",
   "metadata": {},
   "source": [
    "Tfid and bigram only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be16ef8-16bb-4c35-9639-ad7971c8b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_classify_tfid_bigram(corpus, classifier_algorithm):\n",
    " \n",
    "\n",
    "    # Convert SDG labels into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_binary = mlb.fit_transform(corpus['sdg_labels'])\n",
    "    X = corpus['text']\n",
    "    y = y_binary\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2,2), min_df=500, max_features=5000, stop_words='english')\n",
    "    X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "    # train and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    try:\n",
    "        # Check if the classifier accepts a random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm(random_state=42))\n",
    "    except TypeError:\n",
    "        # If not, initialize it without the random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm())\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Use `predict_proba` for classifiers that support it (e.g., MLPClassifier, MultinomialNB)\n",
    "        y_pred_proba = classifier.predict_proba(X_test)\n",
    "        threshold = 0.3\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Use `predict_log_proba` for classifiers that support it (e.g., MultinomialNB)\n",
    "            y_pred_log_proba = classifier.predict_log_proba(X_test)\n",
    "            y_pred_proba = np.exp(y_pred_log_proba)  # Convert log probabilities to probabilities\n",
    "            threshold = 0.3\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        except AttributeError:\n",
    "            # If neither `predict_proba` nor `predict_log_proba` is available, use `predict`\n",
    "            y_pred = classifier.predict(X_test)\n",
    "        \n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a46e3b6-19f8-4f78-9cc8-c9f640bebcbd",
   "metadata": {},
   "source": [
    "tfid and both unigram and bigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a593e688-6b3e-409c-8132-4692dc318b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_classify_tfid_both(corpus, classifier_algorithm):\n",
    " \n",
    "\n",
    "    # Convert SDG labels into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_binary = mlb.fit_transform(corpus['sdg_labels'])\n",
    "    X = corpus['text']\n",
    "    y = y_binary\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=500, max_features=5000, stop_words='english')\n",
    "    X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "    # train and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    try:\n",
    "        # Check if the classifier accepts a random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm(random_state=42))\n",
    "    except TypeError:\n",
    "        # If not, initialize it without the random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm())\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Use `predict_proba` for classifiers that support it (e.g., MLPClassifier, MultinomialNB)\n",
    "        y_pred_proba = classifier.predict_proba(X_test)\n",
    "        threshold = 0.3\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Use `predict_log_proba` for classifiers that support it (e.g., MultinomialNB)\n",
    "            y_pred_log_proba = classifier.predict_log_proba(X_test)\n",
    "            y_pred_proba = np.exp(y_pred_log_proba)  # Convert log probabilities to probabilities\n",
    "            threshold = 0.3\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        except AttributeError:\n",
    "            # If neither `predict_proba` nor `predict_log_proba` is available, use `predict`\n",
    "            y_pred = classifier.predict(X_test)\n",
    "        \n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57feb3ea-c250-437a-b4bd-ba5cf11f2ec8",
   "metadata": {},
   "source": [
    "Then we will define all functions with count vector in one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea14aa9-9a64-4dd9-9b14-0f538d3b38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_classify_count_unigram(corpus, classifier_algorithm):\n",
    " \n",
    "\n",
    "    # Convert SDG labels into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_binary = mlb.fit_transform(corpus['sdg_labels'])\n",
    "    X = corpus['text']\n",
    "    y = y_binary\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,1), min_df=500, max_features=5000, stop_words='english')\n",
    "    X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "    # train and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    try:\n",
    "        # Check if the classifier accepts a random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm(random_state=42))\n",
    "    except TypeError:\n",
    "        # If not, initialize it without the random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm())\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Use `predict_proba` for classifiers that support it (e.g., MLPClassifier, MultinomialNB)\n",
    "        y_pred_proba = classifier.predict_proba(X_test)\n",
    "        threshold = 0.3\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Use `predict_log_proba` for classifiers that support it (e.g., MultinomialNB)\n",
    "            y_pred_log_proba = classifier.predict_log_proba(X_test)\n",
    "            y_pred_proba = np.exp(y_pred_log_proba)  # Convert log probabilities to probabilities\n",
    "            threshold = 0.3\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        except AttributeError:\n",
    "            # If neither `predict_proba` nor `predict_log_proba` is available, use `predict`\n",
    "            y_pred = classifier.predict(X_test)\n",
    "        \n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def sdg_classify_count_bigram(corpus, classifier_algorithm):\n",
    " \n",
    "\n",
    "    # Convert SDG labels into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_binary = mlb.fit_transform(corpus['sdg_labels'])\n",
    "    X = corpus['text']\n",
    "    y = y_binary\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,2), min_df=500, max_features=5000, stop_words='english')\n",
    "    X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "    # train and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    try:\n",
    "        # Check if the classifier accepts a random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm(random_state=42))\n",
    "    except TypeError:\n",
    "        # If not, initialize it without the random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm())\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Use `predict_proba` for classifiers that support it (e.g., MLPClassifier, MultinomialNB)\n",
    "        y_pred_proba = classifier.predict_proba(X_test)\n",
    "        threshold = 0.3\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Use `predict_log_proba` for classifiers that support it (e.g., MultinomialNB)\n",
    "            y_pred_log_proba = classifier.predict_log_proba(X_test)\n",
    "            y_pred_proba = np.exp(y_pred_log_proba)  # Convert log probabilities to probabilities\n",
    "            threshold = 0.3\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        except AttributeError:\n",
    "            # If neither `predict_proba` nor `predict_log_proba` is available, use `predict`\n",
    "            y_pred = classifier.predict(X_test)\n",
    "        \n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def sdg_classify_count_both(corpus, classifier_algorithm):\n",
    " \n",
    "\n",
    "    # Convert SDG labels into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_binary = mlb.fit_transform(corpus['sdg_labels'])\n",
    "    X = corpus['text']\n",
    "    y = y_binary\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,2), min_df=500, max_features=5000, stop_words='english')\n",
    "    X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "    # train and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    try:\n",
    "        # Check if the classifier accepts a random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm(random_state=42))\n",
    "    except TypeError:\n",
    "        # If not, initialize it without the random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm())\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Use `predict_proba` for classifiers that support it (e.g., MLPClassifier, MultinomialNB)\n",
    "        y_pred_proba = classifier.predict_proba(X_test)\n",
    "        threshold = 0.3\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Use `predict_log_proba` for classifiers that support it (e.g., MultinomialNB)\n",
    "            y_pred_log_proba = classifier.predict_log_proba(X_test)\n",
    "            y_pred_proba = np.exp(y_pred_log_proba)  # Convert log probabilities to probabilities\n",
    "            threshold = 0.3\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        except AttributeError:\n",
    "            # If neither `predict_proba` nor `predict_log_proba` is available, use `predict`\n",
    "            y_pred = classifier.predict(X_test)\n",
    "        \n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c47c0-413c-4709-8541-6bbe937ec37a",
   "metadata": {},
   "source": [
    "Since the functionn is defined, we are going to run this function with tfidf vector and on all three classiers mentioned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554a8ba6-ed4a-41ac-b60b-470410d2c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8527707966825836, 'recall': 0.6851078280017713, 'f1_score': 0.6749792924397096, 'accuracy': 0.49434531289268663}\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "metrics = sdg_classify_tfid_unigram(corpus, MultinomialNB)\n",
    "precision1 = metrics['precision']\n",
    "recall1 = metrics['recall']\n",
    "f1_score1 = metrics['f1_score']\n",
    "accuracy1 = metrics['accuracy']\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf5bf8-0bb7-4a0b-8aaf-60b19880afb8",
   "metadata": {},
   "source": [
    "Ridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d22609e-bb6c-46ac-8766-e2461d1b3f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9477046159001423, 'recall': 0.6238309657447632, 'f1_score': 0.650616124541734, 'accuracy': 0.5310379492334757}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "metrics = sdg_classify_tfid_unigram(corpus, lambda: RidgeClassifier(solver='sparse_cg'))\n",
    "precision2 = metrics['precision']\n",
    "recall2 = metrics['recall']\n",
    "f1_score2 = metrics['f1_score']\n",
    "accuracy2 = metrics['accuracy']\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5a1167-f245-4439-9c99-4d531496d0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8998226801820669, 'recall': 0.8801178907518439, 'f1_score': 0.8684987619958717, 'accuracy': 0.7425232470469967}\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "metrics = sdg_classify_tfid_unigram(corpus, lambda: MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=3000, random_state=42))\n",
    "precision3 = metrics['precision']\n",
    "recall3 = metrics['recall']\n",
    "f1_score3 = metrics['f1_score']\n",
    "accuracy3 = metrics['accuracy']\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8548ab4-be7f-411e-ad1f-3b2b35d5521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94202\\AppData\\Local\\Temp\\ipykernel_19484\\4055098208.py:17: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_12808_row1_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_12808\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_12808_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_12808_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_12808_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_12808_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "      <th id=\"T_12808_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_12808_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_12808_row0_col0\" class=\"data row0 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_12808_row0_col1\" class=\"data row0 col1\" >0.852771</td>\n",
       "      <td id=\"T_12808_row0_col2\" class=\"data row0 col2\" >0.685108</td>\n",
       "      <td id=\"T_12808_row0_col3\" class=\"data row0 col3\" >0.674979</td>\n",
       "      <td id=\"T_12808_row0_col4\" class=\"data row0 col4\" >0.494345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_12808_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_12808_row1_col0\" class=\"data row1 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_12808_row1_col1\" class=\"data row1 col1\" >0.947705</td>\n",
       "      <td id=\"T_12808_row1_col2\" class=\"data row1 col2\" >0.623831</td>\n",
       "      <td id=\"T_12808_row1_col3\" class=\"data row1 col3\" >0.650616</td>\n",
       "      <td id=\"T_12808_row1_col4\" class=\"data row1 col4\" >0.531038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_12808_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_12808_row2_col0\" class=\"data row2 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_12808_row2_col1\" class=\"data row2 col1\" >0.899823</td>\n",
       "      <td id=\"T_12808_row2_col2\" class=\"data row2 col2\" >0.880118</td>\n",
       "      <td id=\"T_12808_row2_col3\" class=\"data row2 col3\" >0.868499</td>\n",
       "      <td id=\"T_12808_row2_col4\" class=\"data row2 col4\" >0.742523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cc666e7050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Classifier\": [\"MultinomialNB\", \"RidgeClassifier\", \"MLPClassifier\"],\n",
    "    \"Precision\": [precision1, precision2, precision3],\n",
    "    \"Recall\": [recall1, recall2, recall3],\n",
    "    \"F1-Score\": [f1_score1, f1_score2, f1_score3],\n",
    "    \"Accuracy\": [accuracy1, accuracy2, accuracy3]\n",
    "}\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Boldface numbers above 0.9\n",
    "def highlight_high_values(val):\n",
    "    if val > 0.9:\n",
    "        return f\"font-weight: bold\"  # Bold formatting\n",
    "    return None\n",
    "\n",
    "styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb8f6d-75fd-4484-a926-ec21e1d87473",
   "metadata": {},
   "source": [
    "Now we try count vector with unigram only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d190fde-b6df-4cf7-b4ae-62e670689d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94202\\AppData\\Local\\Temp\\ipykernel_19484\\2457502957.py:31: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b0a4a_row1_col1, #T_b0a4a_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b0a4a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b0a4a_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_b0a4a_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_b0a4a_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_b0a4a_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "      <th id=\"T_b0a4a_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b0a4a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b0a4a_row0_col0\" class=\"data row0 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_b0a4a_row0_col1\" class=\"data row0 col1\" >0.509466</td>\n",
       "      <td id=\"T_b0a4a_row0_col2\" class=\"data row0 col2\" >0.878837</td>\n",
       "      <td id=\"T_b0a4a_row0_col3\" class=\"data row0 col3\" >0.600334</td>\n",
       "      <td id=\"T_b0a4a_row0_col4\" class=\"data row0 col4\" >0.188364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0a4a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b0a4a_row1_col0\" class=\"data row1 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_b0a4a_row1_col1\" class=\"data row1 col1\" >0.966847</td>\n",
       "      <td id=\"T_b0a4a_row1_col2\" class=\"data row1 col2\" >0.474112</td>\n",
       "      <td id=\"T_b0a4a_row1_col3\" class=\"data row1 col3\" >0.499932</td>\n",
       "      <td id=\"T_b0a4a_row1_col4\" class=\"data row1 col4\" >0.384644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0a4a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b0a4a_row2_col0\" class=\"data row2 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_b0a4a_row2_col1\" class=\"data row2 col1\" >0.905297</td>\n",
       "      <td id=\"T_b0a4a_row2_col2\" class=\"data row2 col2\" >0.873023</td>\n",
       "      <td id=\"T_b0a4a_row2_col3\" class=\"data row2 col3\" >0.865050</td>\n",
       "      <td id=\"T_b0a4a_row2_col4\" class=\"data row2 col4\" >0.749937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cc666f0410>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "metrics = sdg_classify_count_unigram(corpus, MultinomialNB)\n",
    "precision1 = metrics['precision']\n",
    "recall1 = metrics['recall']\n",
    "f1_score1 = metrics['f1_score']\n",
    "accuracy1 = metrics['accuracy']\n",
    "\n",
    "# Ridge\n",
    "metrics = sdg_classify_count_unigram(corpus, lambda: RidgeClassifier(solver='sparse_cg'))\n",
    "precision2 = metrics['precision']\n",
    "recall2 = metrics['recall']\n",
    "f1_score2 = metrics['f1_score']\n",
    "accuracy2 = metrics['accuracy']\n",
    "\n",
    "# MLP\n",
    "metrics = sdg_classify_count_unigram(corpus, lambda: MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=3000, random_state=42))\n",
    "precision3 = metrics['precision']\n",
    "recall3 = metrics['recall']\n",
    "f1_score3 = metrics['f1_score']\n",
    "accuracy3 = metrics['accuracy']\n",
    "\n",
    "data = {\n",
    "    \"Classifier\": [\"MultinomialNB\", \"RidgeClassifier\", \"MLPClassifier\"],\n",
    "    \"Precision\": [precision1, precision2, precision3],\n",
    "    \"Recall\": [recall1, recall2, recall3],\n",
    "    \"F1-Score\": [f1_score1, f1_score2, f1_score3],\n",
    "    \"Accuracy\": [accuracy1, accuracy2, accuracy3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Display in Jupyter or export to HTML\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af87b9-ed35-4c4d-8c6b-172ae896bea5",
   "metadata": {},
   "source": [
    "Then we try tfidf with bigram only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e810027-359c-499f-af0f-6eec4f4dd5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94202\\AppData\\Local\\Temp\\ipykernel_19484\\2725283539.py:31: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8a06f_row1_col1, #T_8a06f_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8a06f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8a06f_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_8a06f_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_8a06f_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_8a06f_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "      <th id=\"T_8a06f_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8a06f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8a06f_row0_col0\" class=\"data row0 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_8a06f_row0_col1\" class=\"data row0 col1\" >0.895577</td>\n",
       "      <td id=\"T_8a06f_row0_col2\" class=\"data row0 col2\" >0.097222</td>\n",
       "      <td id=\"T_8a06f_row0_col3\" class=\"data row0 col3\" >0.101383</td>\n",
       "      <td id=\"T_8a06f_row0_col4\" class=\"data row0 col4\" >0.070872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a06f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8a06f_row1_col0\" class=\"data row1 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_8a06f_row1_col1\" class=\"data row1 col1\" >0.996607</td>\n",
       "      <td id=\"T_8a06f_row1_col2\" class=\"data row1 col2\" >0.041255</td>\n",
       "      <td id=\"T_8a06f_row1_col3\" class=\"data row1 col3\" >0.046486</td>\n",
       "      <td id=\"T_8a06f_row1_col4\" class=\"data row1 col4\" >0.028525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8a06f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8a06f_row2_col0\" class=\"data row2 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_8a06f_row2_col1\" class=\"data row2 col1\" >0.955893</td>\n",
       "      <td id=\"T_8a06f_row2_col2\" class=\"data row2 col2\" >0.074221</td>\n",
       "      <td id=\"T_8a06f_row2_col3\" class=\"data row2 col3\" >0.075525</td>\n",
       "      <td id=\"T_8a06f_row2_col4\" class=\"data row2 col4\" >0.044735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cc65a8f680>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "metrics = sdg_classify_tfid_bigram(corpus, MultinomialNB)\n",
    "precision1 = metrics['precision']\n",
    "recall1 = metrics['recall']\n",
    "f1_score1 = metrics['f1_score']\n",
    "accuracy1 = metrics['accuracy']\n",
    "\n",
    "# Ridge\n",
    "metrics = sdg_classify_tfid_bigram(corpus, lambda: RidgeClassifier(solver='sparse_cg'))\n",
    "precision2 = metrics['precision']\n",
    "recall2 = metrics['recall']\n",
    "f1_score2 = metrics['f1_score']\n",
    "accuracy2 = metrics['accuracy']\n",
    "\n",
    "# MLP\n",
    "metrics = sdg_classify_tfid_bigram(corpus, lambda: MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=3000, random_state=42))\n",
    "precision3 = metrics['precision']\n",
    "recall3 = metrics['recall']\n",
    "f1_score3 = metrics['f1_score']\n",
    "accuracy3 = metrics['accuracy']\n",
    "\n",
    "data = {\n",
    "    \"Classifier\": [\"MultinomialNB\", \"RidgeClassifier\", \"MLPClassifier\"],\n",
    "    \"Precision\": [precision1, precision2, precision3],\n",
    "    \"Recall\": [recall1, recall2, recall3],\n",
    "    \"F1-Score\": [f1_score1, f1_score2, f1_score3],\n",
    "    \"Accuracy\": [accuracy1, accuracy2, accuracy3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Display in Jupyter or export to HTML\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d009b-3ad9-4583-9109-e016aef155e0",
   "metadata": {},
   "source": [
    "Count vector and bigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b509fa3c-dc7e-4c0e-bf9e-3e5bca105abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94202\\AppData\\Local\\Temp\\ipykernel_19484\\296348711.py:31: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8dd34_row1_col1, #T_8dd34_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8dd34\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8dd34_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_8dd34_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_8dd34_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_8dd34_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "      <th id=\"T_8dd34_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8dd34_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8dd34_row0_col0\" class=\"data row0 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_8dd34_row0_col1\" class=\"data row0 col1\" >0.891819</td>\n",
       "      <td id=\"T_8dd34_row0_col2\" class=\"data row0 col2\" >0.101784</td>\n",
       "      <td id=\"T_8dd34_row0_col3\" class=\"data row0 col3\" >0.090988</td>\n",
       "      <td id=\"T_8dd34_row0_col4\" class=\"data row0 col4\" >0.045489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dd34_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8dd34_row1_col0\" class=\"data row1 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_8dd34_row1_col1\" class=\"data row1 col1\" >0.994220</td>\n",
       "      <td id=\"T_8dd34_row1_col2\" class=\"data row1 col2\" >0.045286</td>\n",
       "      <td id=\"T_8dd34_row1_col3\" class=\"data row1 col3\" >0.050679</td>\n",
       "      <td id=\"T_8dd34_row1_col4\" class=\"data row1 col4\" >0.030787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dd34_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8dd34_row2_col0\" class=\"data row2 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_8dd34_row2_col1\" class=\"data row2 col1\" >0.953715</td>\n",
       "      <td id=\"T_8dd34_row2_col2\" class=\"data row2 col2\" >0.075367</td>\n",
       "      <td id=\"T_8dd34_row2_col3\" class=\"data row2 col3\" >0.077934</td>\n",
       "      <td id=\"T_8dd34_row2_col4\" class=\"data row2 col4\" >0.050013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cc65cc8320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "metrics = sdg_classify_count_bigram(corpus, MultinomialNB)\n",
    "precision1 = metrics['precision']\n",
    "recall1 = metrics['recall']\n",
    "f1_score1 = metrics['f1_score']\n",
    "accuracy1 = metrics['accuracy']\n",
    "\n",
    "# Ridge\n",
    "metrics = sdg_classify_count_bigram(corpus, lambda: RidgeClassifier(solver='sparse_cg'))\n",
    "precision2 = metrics['precision']\n",
    "recall2 = metrics['recall']\n",
    "f1_score2 = metrics['f1_score']\n",
    "accuracy2 = metrics['accuracy']\n",
    "\n",
    "# MLP\n",
    "metrics = sdg_classify_count_bigram(corpus, lambda: MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=3000, random_state=42))\n",
    "precision3 = metrics['precision']\n",
    "recall3 = metrics['recall']\n",
    "f1_score3 = metrics['f1_score']\n",
    "accuracy3 = metrics['accuracy']\n",
    "\n",
    "data = {\n",
    "    \"Classifier\": [\"MultinomialNB\", \"RidgeClassifier\", \"MLPClassifier\"],\n",
    "    \"Precision\": [precision1, precision2, precision3],\n",
    "    \"Recall\": [recall1, recall2, recall3],\n",
    "    \"F1-Score\": [f1_score1, f1_score2, f1_score3],\n",
    "    \"Accuracy\": [accuracy1, accuracy2, accuracy3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Display in Jupyter or export to HTML\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a2408-48cf-43cf-a6f8-c90e22c8bd40",
   "metadata": {},
   "source": [
    "Tfidf vector and with both unigram and bigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faaaf19f-58ab-415a-adbf-29e69d293bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94202\\AppData\\Local\\Temp\\ipykernel_19484\\103387111.py:31: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_09868_row1_col1, #T_09868_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_09868\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09868_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_09868_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_09868_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_09868_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "      <th id=\"T_09868_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09868_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_09868_row0_col0\" class=\"data row0 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_09868_row0_col1\" class=\"data row0 col1\" >0.851573</td>\n",
       "      <td id=\"T_09868_row0_col2\" class=\"data row0 col2\" >0.693625</td>\n",
       "      <td id=\"T_09868_row0_col3\" class=\"data row0 col3\" >0.681452</td>\n",
       "      <td id=\"T_09868_row0_col4\" class=\"data row0 col4\" >0.497487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09868_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_09868_row1_col0\" class=\"data row1 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_09868_row1_col1\" class=\"data row1 col1\" >0.949590</td>\n",
       "      <td id=\"T_09868_row1_col2\" class=\"data row1 col2\" >0.631492</td>\n",
       "      <td id=\"T_09868_row1_col3\" class=\"data row1 col3\" >0.658599</td>\n",
       "      <td id=\"T_09868_row1_col4\" class=\"data row1 col4\" >0.537070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09868_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_09868_row2_col0\" class=\"data row2 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_09868_row2_col1\" class=\"data row2 col1\" >0.902421</td>\n",
       "      <td id=\"T_09868_row2_col2\" class=\"data row2 col2\" >0.877078</td>\n",
       "      <td id=\"T_09868_row2_col3\" class=\"data row2 col3\" >0.867358</td>\n",
       "      <td id=\"T_09868_row2_col4\" class=\"data row2 col4\" >0.745916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cc652b5010>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "metrics = sdg_classify_tfid_both(corpus, MultinomialNB)\n",
    "precision1 = metrics['precision']\n",
    "recall1 = metrics['recall']\n",
    "f1_score1 = metrics['f1_score']\n",
    "accuracy1 = metrics['accuracy']\n",
    "\n",
    "# Ridge\n",
    "metrics = sdg_classify_tfid_both(corpus, lambda: RidgeClassifier(solver='sparse_cg'))\n",
    "precision2 = metrics['precision']\n",
    "recall2 = metrics['recall']\n",
    "f1_score2 = metrics['f1_score']\n",
    "accuracy2 = metrics['accuracy']\n",
    "\n",
    "# MLP\n",
    "metrics = sdg_classify_tfid_both(corpus, lambda: MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=3000, random_state=42))\n",
    "precision3 = metrics['precision']\n",
    "recall3 = metrics['recall']\n",
    "f1_score3 = metrics['f1_score']\n",
    "accuracy3 = metrics['accuracy']\n",
    "\n",
    "data = {\n",
    "    \"Classifier\": [\"MultinomialNB\", \"RidgeClassifier\", \"MLPClassifier\"],\n",
    "    \"Precision\": [precision1, precision2, precision3],\n",
    "    \"Recall\": [recall1, recall2, recall3],\n",
    "    \"F1-Score\": [f1_score1, f1_score2, f1_score3],\n",
    "    \"Accuracy\": [accuracy1, accuracy2, accuracy3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Display in Jupyter or export to HTML\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b95a27-9d0f-4926-a1a3-0e6c7e8642b9",
   "metadata": {},
   "source": [
    "Lastly, we try count with both unigram and bigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec2d61d-46cb-4d3c-aeb5-d43f6b3ace76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94202\\AppData\\Local\\Temp\\ipykernel_19484\\745890235.py:31: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_51c2e_row1_col1, #T_51c2e_row2_col1 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_51c2e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_51c2e_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_51c2e_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_51c2e_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_51c2e_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "      <th id=\"T_51c2e_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_51c2e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_51c2e_row0_col0\" class=\"data row0 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_51c2e_row0_col1\" class=\"data row0 col1\" >0.502684</td>\n",
       "      <td id=\"T_51c2e_row0_col2\" class=\"data row0 col2\" >0.876304</td>\n",
       "      <td id=\"T_51c2e_row0_col3\" class=\"data row0 col3\" >0.594339</td>\n",
       "      <td id=\"T_51c2e_row0_col4\" class=\"data row0 col4\" >0.181076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51c2e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_51c2e_row1_col0\" class=\"data row1 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_51c2e_row1_col1\" class=\"data row1 col1\" >0.970617</td>\n",
       "      <td id=\"T_51c2e_row1_col2\" class=\"data row1 col2\" >0.482272</td>\n",
       "      <td id=\"T_51c2e_row1_col3\" class=\"data row1 col3\" >0.508094</td>\n",
       "      <td id=\"T_51c2e_row1_col4\" class=\"data row1 col4\" >0.390927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51c2e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_51c2e_row2_col0\" class=\"data row2 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_51c2e_row2_col1\" class=\"data row2 col1\" >0.905131</td>\n",
       "      <td id=\"T_51c2e_row2_col2\" class=\"data row2 col2\" >0.874465</td>\n",
       "      <td id=\"T_51c2e_row2_col3\" class=\"data row2 col3\" >0.866207</td>\n",
       "      <td id=\"T_51c2e_row2_col4\" class=\"data row2 col4\" >0.749812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cc672d9730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "metrics = sdg_classify_count_both(corpus, MultinomialNB)\n",
    "precision1 = metrics['precision']\n",
    "recall1 = metrics['recall']\n",
    "f1_score1 = metrics['f1_score']\n",
    "accuracy1 = metrics['accuracy']\n",
    "\n",
    "# Ridge\n",
    "metrics = sdg_classify_count_both(corpus, lambda: RidgeClassifier(solver='sparse_cg'))\n",
    "precision2 = metrics['precision']\n",
    "recall2 = metrics['recall']\n",
    "f1_score2 = metrics['f1_score']\n",
    "accuracy2 = metrics['accuracy']\n",
    "\n",
    "# MLP\n",
    "metrics = sdg_classify_count_both(corpus, lambda: MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=3000, random_state=42))\n",
    "precision3 = metrics['precision']\n",
    "recall3 = metrics['recall']\n",
    "f1_score3 = metrics['f1_score']\n",
    "accuracy3 = metrics['accuracy']\n",
    "\n",
    "data = {\n",
    "    \"Classifier\": [\"MultinomialNB\", \"RidgeClassifier\", \"MLPClassifier\"],\n",
    "    \"Precision\": [precision1, precision2, precision3],\n",
    "    \"Recall\": [recall1, recall2, recall3],\n",
    "    \"F1-Score\": [f1_score1, f1_score2, f1_score3],\n",
    "    \"Accuracy\": [accuracy1, accuracy2, accuracy3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Display in Jupyter or export to HTML\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5173787-2014-4765-bdab-db79004e03dd",
   "metadata": {},
   "source": [
    "After testing all these classifiers by combining with different preprocessing settings. I find that Ridge Classifier is the best one for precision while MLP is the most ideal one for all metrics. In terms of vectors, count vectors and tfidf vectors are similar. \n",
    "However, there is a huge difference between the unigram only and bigram only while unigram only is way better than bigram only. When using bigram only, recall, f1_score, and accuracy are all unreliable. When using both unigram and bigram, the performance is decent and similar to using unigram only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be227d-b561-4008-83f6-ad1641d24508",
   "metadata": {},
   "source": [
    "To directly extract all the text content from these websites, I just use BeautifulSoup to extract the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "982c6918-f446-4717-a287-01515bbe1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to extract main text content from a web page\n",
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Example: Extract the main content (adjust based on website structure)\n",
    "    main_content = soup.find('body').get_text(separator=\" \", strip=True)  # Extract body text\n",
    "    return main_content\n",
    "\n",
    "# List of URLs\n",
    "urls = [\n",
    "    \"http://gianttortoise.org/en/beyond-tracking\",\n",
    "    \"https://www.dhs.gov/blue-campaign/what-human-trafficking\",\n",
    "    \"https://www.dol.gov/agencies/odep/program-areas/individuals/older-workers\",\n",
    "    \"https://michigantoday.umich.edu/2022/08/26/positively-breaking-the-age-code/\"\n",
    "]\n",
    "\n",
    "# Extract text from each URL\n",
    "text_df2 = pd.DataFrame(columns=['text'])\n",
    "text_df2['text'] = [extract_text_from_url(url) for url in urls]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14909c63-b7ca-46ae-afd4-afb950ae5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df2['sdg_labels'] = text_df.text.apply(assign_sdg_labels)\n",
    "corpus2 = text_df2[['text', 'sdg_labels']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436c409-4f7b-42b2-815c-8762d9f8551c",
   "metadata": {},
   "source": [
    "In the previous section, to reduce the running time of MLP, I set the min_df to 500, which is not applicable here. So I change it to 3 to make sure this function can execute well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c67b68b-7dbc-42e5-9edd-bed8eda0bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdg_classify_tfid_unigram2(corpus, classifier_algorithm):\n",
    " \n",
    "\n",
    "    # Convert SDG labels into binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_binary = mlb.fit_transform(corpus['sdg_labels'])\n",
    "    X = corpus['text']\n",
    "    y = y_binary\n",
    "\n",
    "    # Vectorize text data\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,1), min_df=3, max_features=5000, stop_words='english')\n",
    "    X_transformed = vectorizer.fit_transform(X)\n",
    "\n",
    "    # train and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    try:\n",
    "        # Check if the classifier accepts a random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm(random_state=42))\n",
    "    except TypeError:\n",
    "        # If not, initialize it without the random_state parameter\n",
    "        classifier = OneVsRestClassifier(classifier_algorithm())\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Use `predict_proba` for classifiers that support it (e.g., MLPClassifier, MultinomialNB)\n",
    "        y_pred_proba = classifier.predict_proba(X_test)\n",
    "        threshold = 0.3\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Use `predict_log_proba` for classifiers that support it (e.g., MultinomialNB)\n",
    "            y_pred_log_proba = classifier.predict_log_proba(X_test)\n",
    "            y_pred_proba = np.exp(y_pred_log_proba)  # Convert log probabilities to probabilities\n",
    "            threshold = 0.3\n",
    "            y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        except AttributeError:\n",
    "            # If neither `predict_proba` nor `predict_log_proba` is available, use `predict`\n",
    "            y_pred = classifier.predict(X_test)\n",
    "        \n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Return metrics\n",
    "    metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c210aa3d-582b-4fbc-8f49-9abb1b1c1481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 1 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label 2 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label 3 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 4 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 8 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 1 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label 2 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label 3 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 4 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 8 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 0 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 1 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label 2 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label 3 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 4 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\anaconda3\\envs\\joshymob\\Lib\\site-packages\\sklearn\\multiclass.py:87: UserWarning: Label not 8 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\Users\\94202\\AppData\\Local\\Temp\\ipykernel_19484\\981465517.py:31: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_98378\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_98378_level0_col0\" class=\"col_heading level0 col0\" >Classifier</th>\n",
       "      <th id=\"T_98378_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_98378_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_98378_level0_col3\" class=\"col_heading level0 col3\" >F1-Score</th>\n",
       "      <th id=\"T_98378_level0_col4\" class=\"col_heading level0 col4\" >Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_98378_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_98378_row0_col0\" class=\"data row0 col0\" >MultinomialNB</td>\n",
       "      <td id=\"T_98378_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_98378_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_98378_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_98378_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98378_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_98378_row1_col0\" class=\"data row1 col0\" >RidgeClassifier</td>\n",
       "      <td id=\"T_98378_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_98378_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_98378_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_98378_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_98378_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_98378_row2_col0\" class=\"data row2 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_98378_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_98378_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_98378_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_98378_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cc7295eb70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "metrics = sdg_classify_tfid_unigram2(corpus2, MultinomialNB)\n",
    "precision1 = metrics['precision']\n",
    "recall1 = metrics['recall']\n",
    "f1_score1 = metrics['f1_score']\n",
    "accuracy1 = metrics['accuracy']\n",
    "\n",
    "# Ridge\n",
    "metrics = sdg_classify_tfid_unigram2(corpus2, lambda: RidgeClassifier(solver='sparse_cg'))\n",
    "precision2 = metrics['precision']\n",
    "recall2 = metrics['recall']\n",
    "f1_score2 = metrics['f1_score']\n",
    "accuracy2 = metrics['accuracy']\n",
    "\n",
    "# MLP\n",
    "metrics = sdg_classify_tfid_unigram2(corpus2, lambda: MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=3000, random_state=42))\n",
    "precision3 = metrics['precision']\n",
    "recall3 = metrics['recall']\n",
    "f1_score3 = metrics['f1_score']\n",
    "accuracy3 = metrics['accuracy']\n",
    "\n",
    "data = {\n",
    "    \"Classifier\": [\"MultinomialNB\", \"RidgeClassifier\", \"MLPClassifier\"],\n",
    "    \"Precision\": [precision1, precision2, precision3],\n",
    "    \"Recall\": [recall1, recall2, recall3],\n",
    "    \"F1-Score\": [f1_score1, f1_score2, f1_score3],\n",
    "    \"Accuracy\": [accuracy1, accuracy2, accuracy3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "styled_df = df.style.applymap(highlight_high_values, subset=[\"Precision\", \"Recall\", \"F1-Score\"])\n",
    "\n",
    "# Display in Jupyter or export to HTML\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa8777-dc89-4e11-b12e-ad73e5e4ff3a",
   "metadata": {},
   "source": [
    "Since the content from these websites are not SDG-related, it shows that all classfiers are not ideal since I use SDGs as my labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
